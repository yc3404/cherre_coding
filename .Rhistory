install.packages("FactoMineR")
library(FactoMineR)
pca <- PCA(shop_time,scale.unit=TRUE)
pca <- PCA(shop_time%>%select(-c(order_delivery_month,member_substitution_preference,shopper_gender)),scale.unit=TRUE)
dimdesc(pca)
install.packages("dummies")
library(dummies)
str(shop_time)
new_shop <- dummy.data.frame(shop_time, names = c("order_delivery_month","shopper_gender","member_substitution_preference"))
str(new_shop)
prin_comp <- prcomp(new_shop, scale. = T)
#load data
shop_time <- read.table("shipt_takehome_shop_time.tsv",sep="\t",header=TRUE)
#check data
summary(shop_time)
str(shop_time)
#check duplicates
length(unique(shop_time$order_id)) == length(shop_time$order_id)
#check NA and deal with NA
#By inspecting the summary, we can see shopper_num_prev_shops,shopper_num_prev_shops_at_store,shopper_pick_rate_min,shopper_yob,shopper_age and actual_shopping_duration_min columns have missing values. Among those columns, shopper_age has the most amount of missing values, which is 10561/250000 = 4% of the whole data. Because it only consists of 4%, so we can safely remove all these missing values.
shop_time <- na.omit(shop_time)
#Remove outliers
#I tried to remove outliers that are outside 3 standard deviation of the mean, but that left us with a dataset of around 40000 variables, which excludes about 80% of the data. Therefore, I decided not to remove them.
#PCA
library(dummies)
new_shop <- dummy.data.frame(shop_time, names = c("order_delivery_month","shopper_gender","member_substitution_preference"))
prin_comp <- prcomp(new_shop, scale. = T)
summary(new_shop)
prin_comp <- prcomp(new_shop%>%select(-cat_other_unknown), scale. = T)
std_dev <- prin_comp$sdev
pr_var <- std_dev^2
pr_var[1:10]
prop_varex <- pr_var/sum(pr_var)
plot(prop_varex, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
dim(new_shop)
train.data <- data.frame(y=new_shop$actual_shopping_duration_min,prin_comp$x)
View(train.data)
train.data <- tran.data[,1:41]
train.data <- train.data[,1:41]
c1 <- cor(new_shop,new_shop,method="pearson")
c1
cor_df<- data.frame(cor=c1[1:40,41], varn = names(c1[1:40,41]))
cor_df<- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs, type="l")
cor_df %>% filter(cor_abs>0.1)
dim(c1)
cor_df<- data.frame(cor=c1[1:51,52], varn = names(c1[1:51,52]))
cor_df<- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
train.data <- train.data[,1:41]
cor_df %>% filter(cor_abs>0.1)
View(cor_df)
c2 <- cor(new_shop)
c2
corrplot(c2)
library(corrplot)
corrplot(c2)
library(ggcorrplot)
devtools::install_github("kassambara/ggcorrplot")
install.packages("ggcorrplot")
library(ggcorrplot)
ggcorrplot(c2)
#feature selection based on correlation
cor_tds <- cor(new_shop)
cor_df<- data.frame(cor=cor_tds[1:51,52], varn = names(cor_tds[1:51,52]))
cor_df<- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs, type="l")
plot(cor_df$cor_abs, type="l")
cor_df %>% filter(cor_abs >=0.05)
cor_df %>% filter(cor_abs >=0.04)
cor_df %>% filter(cor_abs >=0.02)
list_varn <- cor_df %>% filter(cor_abs>0.02)
filter_df <- data.frame(new_shop) %>% select(y,one_of(as.character(list_varn$varn)))
filter_df <- data.frame(new_shop) %>% select(actual_shopping_duration_min,one_of(as.character(list_varn$varn)))
View(filter_df)
names(filter_df)
y3 <- filter_df$actual_shopping_duration_min[1:1000]
x3 <- filter_df[1:1000,2:28]
fit3 <- randomForest(y=y3,x=x3,mtry=3,importance=TRUE,do.trace=10)
fit3
fit3 <- randomForest(y=y3,x=x3,importance=TRUE,do.trace=10)
fit3
plot(fit3)
which.min(fit3$mse)
fit3 <- randomForest(y=y3,x=x3,ntree=1,importance=TRUE,do.trace=10)
fit3
fit3 <- randomForest(y=y3,x=x3,ntree=200,importance=TRUE,do.trace=10)
fit3
plot(fit3$mse)
fit3 <- randomForest(y=y3,x=x3,ntree=100,importance=TRUE,do.trace=10)
fit3
y3 <- filter_df$actual_shopping_duration_min[1:10000]
x3 <- filter_df[1:10000,2:28]
fit3 <- randomForest(y=y3,x=x3,ntree=100,importance=TRUE,do.trace=10)
fit3
train_sample <- sample(nrow(filter_df), size = nrow(filter_df)*0.66)
train_new <-  filter_df[train_sample,]
test_new <-  filter_df[-train_sample,]
y3 <- train_new$actual_shopping_duration_min[1:10000]
x3 <- train_new[1:10000,2:28]
fit3 <- randomForest(y=y3,x=x3,ntree=100,importance=TRUE,do.trace=10)
fit3
pd3 <- predict(fit3,test_new[1:10000,])
MSE(pd3,y3)
varImpPlot(fit3)
train_sample <- sample(nrow(filter_df), size = nrow(filter_df)*0.66)
train_new <-  filter_df[train_sample,]
test_new <-  filter_df[-train_sample,]
y3 <- train_new$actual_shopping_duration_min[1:20000]
x3 <- train_new[1:20000,2:28]
fit3 <- randomForest(y=y3,x=x3,ntree=100,importance=TRUE,do.trace=10)
pd3 <- predict(fit3,test_new[1:20000,])
fit3
bestmtry <- tuneRF(x3,y3,stepFactor = 1.5,improve=1e-5,ntree=100)
print(bestmtry)
fit3 <- randomForest(y=y3,x=x3,mtry=13,ntree=100,importance=TRUE,do.trace=10)
print(fit3)
pd3 <- predict(fit3,test_new[1:20000,])
RMSE <- sqrt(sum((pd3 - test$actual_shopping_duration_min)^2)/length(pd3))
print(RMSE)
RMSE <- sqrt(sum((pd3 - test_new$actual_shopping_duration_min)^2)/length(pd3))
print(RMSE)
print(RMSE/mean(test_new$actual_shopping_duration_min))
length(pd3)
dim(test_new)
RMSE <- sqrt(sum((pd3 - test_new$actual_shopping_duration_min[1:20000])^2)/length(pd3))
print(RMSE)
print(RMSE/mean(test_new$actual_shopping_duration_min[1:20000]))
train_sample <- sample(nrow(filter_df), size = nrow(filter_df)*0.66)
train_new <-  filter_df[train_sample,]
test_new <-  filter_df[-train_sample,]
y3 <- train_new$actual_shopping_duration_min
x3 <- train_new[,2:28]
fit3 <- randomForest(y=y3,x=x3,mtry=13,ntree=100,importance=TRUE,do.trace=10)
fit3
plot(fit3)
which.min(fit3$mse)
pd3 <- predict(fit3,test_new)
RMSE <- sqrt(sum((pd3 - test_new$actual_shopping_duration_min)^2)/length(pd3))
print(RMSE)
print(RMSE/mean(test_new$actual_shopping_duration_min))
#load libraries
if (!require("tidyverse")) install.packages("tidyverse");library(tidyverse)
if (!require("imputeTS")) install.packages("imputeTS");library(imputeTS)
if (!require("randomForest")) install.packages("randomForest");library(randomForest)
if (!require("dummies")) install.packages("dummies");library(dummies)
new_shop <- dummy.data.frame(shop_time, names = c("order_delivery_month","member_substitution_preference","shopper_gender"))
#feature selection based on correlation
cor_tds <- cor(new_shop)
cor_df<- data.frame(cor=cor_tds[1:51,52], varn = names(cor_tds[1:51,52]))
cor_df<- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs, type="l")
list_varn <- cor_df %>% filter(cor_abs>0.02)
filter_df <- data.frame(new_shop) %>% select(actual_shopping_duration_min,one_of(as.character(list_varn$varn)))
model <- lm(actual_shopping_duration_min~.,data=train_new)
summary(model)
pd_lm <- predict(model,test_new)
RMSE_lm <- sqrt(sum((pd_lm - test_new$actual_shopping_duration_min)^2)/length(pd_lm))
RMSE_lm
RMSE_mean_lm <- RMSE_lm/mean(test_new$actual_shopping_duration_min)
RMSE_mean_lm
names(test_new)
pd_base <- (test_new$order_num_order_lines)*2.5
RMSE_base <- sqrt(sum((pd_base- test_new$actual_shopping_duration_min)^2)/length(pd_base))
RMSE_base
RMSE_mean_base <- RMSE_base/mean(test_new$actual_shopping_duration_min)
tb <- data.frame(c(RMSE_rf,RMSE_lm,RMSE_base),c(RMSE_mean_rf,RMSE_mean_lm,RMSE_mean_base),byrow=TRUE)
RMSE_rf <- sqrt(sum((pd3 - test_new$actual_shopping_duration_min)^2)/length(pd3))
RMSE_mean_rf <- RMSE_rf/mean(test_new$actual_shopping_duration_min)
tb <- data.frame(c(RMSE_rf,RMSE_lm,RMSE_base),c(RMSE_mean_rf,RMSE_mean_lm,RMSE_mean_base),byrow=TRUE)
tb
tb <- data.frame(c(RMSE_rf,RMSE_mean_rf),c(RMSE_lm,RMSE_mean_lm))
tb
colnames(tb) <- c("Random Forest","Linear Regression","Baseline")
tb
tb <- data.frame(c(RMSE_rf,RMSE_mean_rf),c(RMSE_lm,RMSE_mean_lm),c(RMSE_base,RMSE_mean_base))
colnames(tb) <- c("Random Forest","Linear Regression","Baseline")
tb
datatable(tb)
#load libraries
if (!require("tidyverse")) install.packages("tidyverse");library(tidyverse)
if (!require("imputeTS")) install.packages("imputeTS");library(imputeTS)
if (!require("randomForest")) install.packages("randomForest");library(randomForest)
if (!require("dummies")) install.packages("dummies");library(dummies)
if (!require("DT")) install.packages("DT");library(DT)
datatable(tb)
tb <- data.frame(c(round(RMSE_rf,2),round(RMSE_mean_rf,2)),c(round(RMSE_lm,2),round(RMSE_mean_lm,2)),c(round(RMSE_base,2),round(RMSE_mean_base,2)))
colnames(tb) <- c("Random Forest","Linear Regression","Baseline")
datatable(tb)
rownames(tb) <- c("RMSE","RMSE/mean")
datatable(tb)
setwd("~/Desktop/cherre")
knitr::opts_chunk$set(echo = TRUE)
if (!require("RSQLite")) install.packages("RSQLite");library(RSQLite)
if (!require("DBI")) install.packages("DBI");library(DBI)
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
#query to fetch all data from the database
q1 <- dbSendQuery(con, "SELECT * FROM frequent_browsers")
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
#query to fetch all data from the database
q1 <- dbSendQuery(con, "SELECT * FROM frequent_browsers")
dbFetch(q1,n=-1)
src_dbi(con)
#Load libraries
if (!require("RSQLite")) install.packages("RSQLite");library(RSQLite)
if (!require("DBI")) install.packages("DBI");library(DBI)
if (!require("dbplyr")) install.packages("dbplyr");library(dbplyr)
if (!require("dplyr")) install.packages("dplyr");library(dplyr)
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#query to fetch all data from the database
q1 <- dbSendQuery(con, "SELECT * FROM frequent_browsers")
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
tbl(con,sql("SELECT * FROM frequent_browsers"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
tbl(con,sql("SELECT * FROM people"))
tbl(con,sql("SELECT * FROM slite_sequence"))
tbl(con,sql("SELECT * FROM sqlite_sequence"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are
tbl(con,sql("SELECT * FROM sites"))
tbl(con,sql("SELECT * FROM visits"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC") LIMIT 10)
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC LIMT 10"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC OFFSET 0 ROWS FETCH NEXT 10 ROWS ONLY"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10"))
tbl(con,sql("SELECT * FROM people"))
tbl(con,sql("SELECT * FROM people"))%>%View()
tbl(con,sql("SELECT * FROM people"))
tbl(con,sql("SELECT * FROM sites"))
tbl(con,sql("SELECT * FROM visits"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("INSERT INTO 'frequent_browsers' SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10;"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("UPDATE frequent_browsers
SET
(person_id,num_sites_visited) = (SELECT personId, COUNT(*) FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10);"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("With 10frequentusers AS
(SELECT personId, COUNT(*) AS ct FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10)
UPDATE frequent_browsers
SET
person_id = (select personId FROM 10frequentusers),
num_sites_visited = (select ct FROM 10frequentusers);"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql(";With 10frequentusers AS
(SELECT personId, COUNT(*) AS ct FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10)
UPDATE frequent_browsers
SET
person_id = (select personId FROM 10frequentusers),
num_sites_visited = (select ct FROM 10frequentusers);"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("With 10fr AS
(SELECT personId, COUNT(*) AS ct FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10)
UPDATE frequent_browsers
SET
person_id = (select personId FROM 10fr),
num_sites_visited = (select ct FROM 10fr);"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("INSERT INTO frequent_browsers SELECT personId, COUNT(*) AS ct FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("UPDATE frequent_browsers
SET person_id = SELECT personId FROM visits,
num_sites_visited = SELECT COUNT(*) FROM visits"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("INSERT INTO frequent_browsers (person_id,num_sites_visited)
SELECT personId, COUNT(*) AS ct FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("INSERT INTO frequent_browsers (person_id,num_sites_visited) SELECT personId, COUNT(*) AS ct FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("INSERT INTO frequent_browsers (person_id) SELECT personId FROM visits"))
#set up database
con = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(con)
#we can see that there are people, sites, visits tables
tbl(con,sql("INSERT INTO frequent_browsers (person_id) SELECT personId FROM visits;"))
?dbExecute
dbExecute(con,"INSERT INTO frequent_browsers (person_id) SELECT personId FROM visits;")
dbExecute(con,"INSERT INTO frequent_browsers (person_id,num_sites_visited) SELECT personId, COUNT(*) AS ct FROM visits GROUP BY personId ORDER BY count(*) DESC LIMIT 0,10")
tbl(con,sql("SELECT * FROM frequent_browsers"))
fit3
varImpPlot(fit3)
?varImpPlot
install.packages("flexdashboard")
library(DT)
library(flexdashboard)
datatable(tbl(con,sql("SELECT * FROM visits")))
datatable(as.data.frame(tbl(con,sql("SELECT * FROM visits"))))
?datatable
src_dbi(con)
names(filter_df)
if (!require("flexdashboard")) install.packages("flexdashboard");library(flexdashboard)
testdb = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(testdb)
dbDisconnect(testdb)
dbDisconnect(con)
closeAllConnections()
if (!require("flexdashboard")) install.packages("flexdashboard");library(flexdashboard)
#Display the top 10 people names
tbl(testdb,sql("SELECT first_name, last_name FROM people JOIN frequent_browsers ON people.id = frequent_browsers.person_id"))
#Load libraries
if (!require("RSQLite")) install.packages("RSQLite");library(RSQLite)
if (!require("DBI")) install.packages("DBI");library(DBI)
if (!require("dbplyr")) install.packages("dbplyr");library(dbplyr)
if (!require("dplyr")) install.packages("dplyr");library(dplyr)
if (!require("DT")) install.packages("DT");library(DT)
#set up database
testdb = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(testdb)
dbExecute(testdb,"INSERT INTO frequent_browsers (person_id,num_sites_visited) SELECT personId, COUNT(distinct siteId) AS ct FROM visits GROUP BY personId ORDER BY count(distinct siteId) DESC LIMIT 0,10")
#Display the top 10 people names
tbl(testdb,sql("SELECT first_name, last_name FROM people JOIN frequent_browsers ON people.id = frequent_browsers.person_id"))
dbDisconnect(testdb)
if (!require("flexdashboard")) install.packages("flexdashboard");library(flexdashboard)
#Load libraries
if (!require("RSQLite")) install.packages("RSQLite");library(RSQLite)
if (!require("DBI")) install.packages("DBI");library(DBI)
if (!require("dbplyr")) install.packages("dbplyr");library(dbplyr)
if (!require("dplyr")) install.packages("dplyr");library(dplyr)
if (!require("DT")) install.packages("DT");library(DT)
#set up database
testdb = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(testdb)
datatable(as.data.frame(tbl(testdb,sql("SELECT * FROM people"))))
#Load libraries
if (!require("RSQLite")) install.packages("RSQLite");library(RSQLite)
if (!require("DBI")) install.packages("DBI");library(DBI)
if (!require("dbplyr")) install.packages("dbplyr");library(dbplyr)
if (!require("dplyr")) install.packages("dplyr");library(dplyr)
if (!require("DT")) install.packages("DT");library(DT)
#set up database
testdb = dbConnect(SQLite(), dbname="testdb.db")
src_dbi(testdb)
all <- as.data.frame(tbl(testdb,sql("SELECT id, count(*) from sites where count(*) > 1")))
all <- as.data.frame(tbl(testdb,sql("SELECT id, count(*) from sites))
all <- as.data.frame(tbl(testdb,sql("SELECT id, count(*) from sites")))
all
all <- as.data.frame(tbl(testdb,sql("SELECT id, count(*) from sites group by id having count(*) > 1")))
all
all2 <- as.data.frame(tbl(testdb,sql("SELECT id, count(*) from sites group by first_name,last_name having count(*) > 1")))
all2 <- as.data.frame(tbl(testdb,sql("SELECT id, count(*) from people group by first_name,last_name having count(*) > 1")))
all2
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
a1
View(a1)
a1 %>% group_by(first_name,last_name) %>% add_count(siteId) %>% View()
a1 %>% group_by(first_name,last_name) %>% add_count(siteId) %>% arrange(desc(n))%>%View()
a1 %>% filter(first_name == "Alena" & last_name == "Jacobson") %>% View()
a1 %>% filter(first_name == "Alena" & last_name == "Jacobson")%>%mutate(id=30)%>%View()
a2 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
View(a2)
a2 %>% group_by(id)%>%add_count(siteId)%>%View()
a2 %>% ungroup() %>% group_by(id)%>% add_count(siteId)%>%View()
a2 %>% ungroup() %>% group_by(id)%>% summarize(count=n())%>%View()
23+16
a2 %>% ungroup() %>% group_by(id)%>% summarize(count=n_distinct())%>%View()
a2 %>% ungroup() %>% group_by(id)%>% summarize(count=n_distinct(siteId))%>%View()
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
#change the id of Alena Jacobson to 30
a1 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
#calculate the 10 people who visited most sites
a2 <- a1 %>% group_by(id) %>% summarize(count=n_distinct(siteI))%>%arrange(desc(count))%>%top_n
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
#change the id of Alena Jacobson to 30
a1 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
#calculate the 10 people who visited most sites
a2 <- a1 %>% group_by(id) %>% summarize(count=n_distinct(site))%>%arrange(desc(count))%>%top_n
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
#change the id of Alena Jacobson to 30
a1 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
#calculate the 10 people who visited most sites
a2 <- a1 %>% group_by(id) %>% summarize(count=n_distinct(siteId))%>%arrange(desc(count))%>%top_n
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
#change the id of Alena Jacobson to 30
a1 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
#calculate the 10 people who visited most sites
a2 <- a1 %>% group_by(id) %>% summarize(count=n_distinct(siteId))%>%arrange(desc(count))%>%top_n(count)
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
#change the id of Alena Jacobson to 30
a1 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
#calculate the 10 people who visited most sites
a2 <- a1 %>% group_by(id) %>% summarize(count=n_distinct(siteId))%>%arrange(desc(count))
View(a2)
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
#change the id of Alena Jacobson to 30
a1 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
#calculate the 10 people who visited most sites
a2 <- a1 %>% group_by(id) %>% summarize(count=n_distinct(siteId))%>%arrange(desc(count))%>%slice(10)
View(a2)
a1 <- as.data.frame(tbl(testdb,sql("SELECT id, first_name,last_name, siteId FROM people JOIN visits ON people.id = visits.personId")))
#change the id of Alena Jacobson to 30
a1 <- a1 %>% mutate(id=replace(id,first_name=="Alena"&last_name=="Jacobson",30))
#calculate the 10 people who visited most sites
a2 <- a1 %>% group_by(id) %>% summarize(count=n_distinct(siteId))%>%arrange(desc(count))%>%slice(c(1:10))
View(a2)
tbl(testdb,sql("SELECT first_name,last_name FROM people WHERE id=30"))
str(a2)
dbWriteTable(testdb,"frequent_browsers",a2,append=TRUE)
a2
dbWriteTable(testdb,"frequent_browsers",a2,append=TRUE)
a2
testdb
?dbWriteTable
colnames(a2) <- c('person_id', 'num_sites_visited')
a2
dbWriteTable(testdb,"frequent_browsers",a2,append=TRUE)
names(filter_df)
knitr::opts_chunk$set(echo = TRUE)
#load libraries
if (!require("tidyverse")) install.packages("tidyverse");library(tidyverse)
if (!require("imputeTS")) install.packages("imputeTS");library(imputeTS)
if (!require("randomForest")) install.packages("randomForest");library(randomForest)
if (!require("dummies")) install.packages("dummies");library(dummies)
if (!require("DT")) install.packages("DT");library(DT)
#load data
shop_time <- read.table("shipt_takehome_shop_time.tsv",sep="\t",header=TRUE)
#check data
summary(shop_time)
str(shop_time)
#check duplicates
length(unique(shop_time$order_id)) == length(shop_time$order_id)
#check NA and deal with NA
#By inspecting the summary, we can see shopper_num_prev_shops,shopper_num_prev_shops_at_store,shopper_pick_rate_min,shopper_yob,shopper_age and actual_shopping_duration_min columns have missing values. Among those columns, shopper_age has the most amount of missing values, which is 10561/250000 = 4% of the whole data. Because it only consists of 4%, so we can safely remove all these missing values.
shop_time <- na.omit(shop_time)
#Remove outliers
#I tried to remove outliers that are outside 3 standard deviation of the mean, but that left us with a dataset of around 40000 variables, which excludes about 80% of the data. Therefore, I decided not to remove them.
#Because there are factors in the data, we need to dummify them
new_shop <- dummy.data.frame(shop_time, names = c("order_delivery_month","member_substitution_preference","shopper_gender"))
#feature selection based on correlation
cor_tds <- cor(new_shop)
cor_df<- data.frame(cor=cor_tds[1:51,52], varn = names(cor_tds[1:51,52]))
cor_df<- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs, type="l")
#From the plot I think it is reasonable to set the cutoff at 0.02
#so we select columns with correlation greater than 0.02
list_varn <- cor_df %>% filter(cor_abs>0.02)
filter_df <- data.frame(new_shop) %>% select(actual_shopping_duration_min,one_of(as.character(list_varn$varn)))
names(filter_df)
filtered_df %>% View()
filter_df %>% View()
#Display the top 10 people names
datatable(as.data.frame(tbl(testdb,sql("SELECT first_name, last_name FROM people JOIN frequent_browsers ON people.id = frequent_browsers.person_id"))))
#Finally remember to disconnect from the database
dbDisconnect(testdb)
